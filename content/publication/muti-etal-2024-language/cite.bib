@inproceedings{muti-etal-2024-language,
 abstract = {We propose misogyny detection as an Argumentative Reasoning task
and we investigate the capacity of large language models (LLMs) to understand
the implicit reasoning used to convey misogyny in both Italian and English. The
central aim is to generate the missing reasoning link between a message and the
implied meanings encoding the misogyny. Our study uses argumentation theory as a
foundation to form a collection of prompts in both zero-shot and few-shot
settings. These prompts integrate different techniques, including
chain-of-thought reasoning and augmented knowledge. Our findings show that LLMs
fall short on reasoning capabilities about misogynistic comments and that they
mostly rely on their implicit knowledge derived from internalized common
stereotypes about women to generate implied assumptions, rather than on
inductive reasoning.},
 address = {Miami, Florida, USA},
 author = {Muti, Arianna  and
Ruggeri, Federico  and
Khatib, Khalid Al  and
Barrón-Cedeño, Alberto  and
Caselli, Tommaso},
 booktitle = {Proceedings of the 2024 Conference on Empirical Methods in
Natural Language Processing},
 doi = {10.18653/v1/2024.emnlp-main.1174},
 editor = {Al-Onaizan, Yaser  and
Bansal, Mohit  and
Chen, Yun-Nung},
 month = {November},
 pages = {21091--21107},
 publisher = {Association for Computational Linguistics},
 title = {Language is Scary when Over-Analyzed: Unpacking Implied
Misogynistic Reasoning with Argumentation Theory-Driven Prompts},
 url = {https://aclanthology.org/2024.emnlp-main.1174/},
 year = {2024}
}
