@inproceedings{WOS:001352265600019,
 abstract = {We describe the fourth edition of the CheckThat! Lab, part of the 
2021 Conference and Labs of the Evaluation Forum (CLEF). The lab evaluates
technology supporting tasks related to factuality, and covers Arabic,  
Bulgarian, English, Spanish, and Turkish. Task 1 asks to predict which
posts in a Twitter stream are worth fact-checking, focusing on COVID-19
and politics (in all five languages). Task 2 asks to determine whether a
claim in a tweet can be verified using a set of previously fact-checked
claims (in Arabic and English). Task 3 asks to predict the veracity of a
news article and its topical domain (in English). The evaluation is based on 
mean average precision or precision at rank k for the ranking
tasks, and macro-F1 for the classification tasks. This was the most
popular CLEF-2021 lab in terms of team registrations: 132 teams. Nearly
one-third of them participated: 15, 5, and 25 teams submitted official
runs for tasks 1, 2, and 3, respectively.},
 author = {Nakov, Preslav and Da San Martino, Giovanni and Elsayed, Tamer and
Barrón-Cedeño, Alberto and Miguez, Ruben and Shaar, Shaden and 
Alam, Firoj and Haouari, Fatima and Hasanain, Maram and Mansour, Watheq and
Hamdan, Bayan and Ali, Zien Sheikh and Babulkov, Nikolay and Nikolov,
Alex and Shahi, Gautam Kishore and Struss, Julia Maria and Mandl, Thomas
and Kutlu, Mucahid and Kartal, Yavuz Selim},
 booktitle = {EXPERIMENTAL IR MEETS MULTILINGUALITY, MULTIMODALITY, AND 
INTERACTION,
CLEF 2021},
 doi = {10.1007/978-3-030-85251-1_19},
 editor = {Candan, KS and Ionescu, B and Goeuriot, L and Larsen, B and Muller, 
H   and Joly, A and Maistro, M and Piroi, F and Faggioli, G and Ferro, N},
 eissn = {1611-3349},
 isbn = {978-3-030-85250-4; 978-3-030-85251-1},
 issn = {0302-9743},
 pages = {264-291},
 series = {Lecture Notes in Computer Science},
 title = {Overview of the CLEF-2021 CheckThat! Lab on Detecting Check-Worthy
Claims, Previously Fact-Checked Claims, and Fake News},
 volume = {12880},
 year = {2021}
}
