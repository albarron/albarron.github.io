{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CodgW4tN_iV0"
      },
      "source": [
        "# DIT Natural Language Processing lesson 2025\n",
        "\n",
        "## Using character-level representations for generation\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model was trained in lesson 19. Now we simply load it and model and run it"
      ],
      "metadata": {
        "id": "ek3jDE9-o-Y_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6NyOEJmW_iV1"
      },
      "outputs": [],
      "source": [
        "# Importing the dependencies\n",
        "\n",
        "import nltk\n",
        "import numpy as np\n",
        "import random\n",
        "import sys\n",
        "\n",
        "from keras.models import model_from_json\n",
        "from nltk.corpus import gutenberg"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This max len can be modified, because this is an LSTM\n",
        "MAXLEN = 40\n",
        "\n",
        "# Files with network architecture and weights\n",
        "MODEL_JSON = \"shakes_lstm_model.json\"\n",
        "MODEL_WEIGHTS = \"shakes_lstm_5.weights.h5\""
      ],
      "metadata": {
        "id": "fNSrrP_MrCbc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the _text_ to serve as seed (prompt), as well as the dictionaries to codify the input and decodify the output"
      ],
      "metadata": {
        "id": "T1_V14TrqlLO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('gutenberg')"
      ],
      "metadata": {
        "id": "PTIbFG2AtGCP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = ''\n",
        "for txt in gutenberg.fileids():\n",
        "    if 'shakespeare' in txt:\n",
        "        text += gutenberg.raw(txt).lower()\n",
        "chars = sorted(list(set(text)))\n",
        "\n",
        "# dictionary from character to index\n",
        "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "\n",
        "# distionary from index to character\n",
        "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
        "\n",
        "print('corpus length: {} total chars: {}'.format(len(text), len(chars)))\n",
        "\n",
        "print(text[:500])\n",
        "print(char_indices)\n",
        "print(indices_char)"
      ],
      "metadata": {
        "id": "kMeaxul7qraL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1B09OluV_iV3"
      },
      "source": [
        "**Loading the pre-trained network**\n",
        "\n",
        "The structure and weight files have to be loaded beforehand.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oaas6TXz_iV3"
      },
      "outputs": [],
      "source": [
        "with open(MODEL_JSON, \"r\") as json_file:\n",
        "    json_string = json_file.read()\n",
        "model = model_from_json(json_string)\n",
        "model.load_weights(MODEL_WEIGHTS)\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqZaq9I5_iV4"
      },
      "source": [
        "**Temperature**\n",
        "\n",
        "temperature > 1 : more diverse outcome\n",
        "\n",
        "temperature < 1 : more strict (try to \"copy\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    \"\"\"Sampler to generate character sequences\"\"\"\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "\n",
        "    # produces a number of random outcomes,\n",
        "    # given a probability distribution\n",
        "    # n=1    number of experiments\n",
        "    # preds  sequence of probabilities\n",
        "    # size=1\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "metadata": {
        "id": "CxQieykjqEsq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_index = random.randint(0, len(text) - MAXLEN - 1)\n",
        "for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
        "    print()\n",
        "    print('----- diversity:', diversity)\n",
        "    # Getting a random starting text\n",
        "    sentence = text[start_index: start_index + MAXLEN]\n",
        "    generated = ''\n",
        "    generated += sentence\n",
        "\n",
        "    print('----- Generating with seed: \"' + sentence + '\"')\n",
        "    sys.stdout.write(generated)\n",
        "    for i in range(400):\n",
        "        # one-hot representation\n",
        "        x = np.zeros((1, MAXLEN, len(chars)))\n",
        "        for t, char in enumerate(sentence):\n",
        "            x[0, t, char_indices[char]] = 1.\n",
        "\n",
        "        # Producing the prediction\n",
        "        preds = model.predict(x, verbose=0)[0]\n",
        "        next_index = sample(preds, diversity)\n",
        "\n",
        "        # looking up the next character and adding it\n",
        "        next_char = indices_char[next_index]\n",
        "        generated += next_char\n",
        "\n",
        "        #updating the seed\n",
        "        sentence = sentence[1:] + next_char\n",
        "\n",
        "        sys.stdout.write(next_char)\n",
        "        sys.stdout.flush()  # to display it right away\n",
        "    print()\n",
        "\n",
        "# lower values should look \"more Shakesperean\""
      ],
      "metadata": {
        "id": "HFzgevX1qGaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Homework\n",
        "\n",
        "1. Try with shorter/longer contextual sequences\n",
        "2. Build a model that tries to mimic Dante"
      ],
      "metadata": {
        "id": "jtONEj3AqOl6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**End of the notebook**"
      ],
      "metadata": {
        "id": "HVE9t5f-qU4q"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vlivtKU0qVRO"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}