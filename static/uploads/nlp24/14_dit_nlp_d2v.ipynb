{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShFrNeemlOZZ"
      },
      "source": [
        "# DIT NLP Lesson 2024\n",
        "\n",
        "## Doc2vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sySh_AMUlOZb"
      },
      "outputs": [],
      "source": [
        "# Importing dependencies\n",
        "\n",
        "# Spacy Italian models (to split by sentence)\n",
        "from spacy.lang.it import Italian\n",
        "\n",
        "\n",
        "#  gensim's dependencies to compute doc to vec\n",
        "from gensim.models.doc2vec import TaggedDocument, Doc2Vec\n",
        "# gensim crude tokenizer that ignores one-letter words and punctuation\n",
        "from gensim.utils import simple_preprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sl4rck9IlOZc"
      },
      "outputs": [],
      "source": [
        "# Finding out the number of cores available\n",
        "import multiprocessing\n",
        "num_cores = multiprocessing.cpu_count()\n",
        "num_cores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bYd-pOX9lOZd"
      },
      "outputs": [],
      "source": [
        "# text = \"\"\"Doha was founded in the 1820s as an offshoot of Al Bidda. It was officially declared as the country's capital in 1971, when Qatar gained independence from being a British protectorate.[4] As the commercial capital of Qatar and one of the emergent financial centers in the Middle East, Doha is considered a beta-level global city by the Globalization and World Cities Research Network. Doha accommodates Education City, an area devoted to research and education, and Hamad Medical City, an administrative area of medical care. It also includes Doha Sports City, or Aspire Zone, an international sports destination that includes Khalifa International Stadium, a stadium for the 2022 FIFA World Cup; Hamad Aquatic Centre; and the Aspire Dome. \"\"\"\n",
        "\n",
        "# https://it.wikipedia.org/wiki/Doha, as in November 2022\n",
        "text = \"Doha è la capitale e la città più popolata dello stato del Qatar. Si trova sul \" + \\\n",
        "    \"Golfo Persico e aveva nel 2015 una popolazione di 956 460 abitanti. È la più grande città \" + \\\n",
        "    \"del Qatar e, con la sua area urbana e suburbana, ospita circa il 60% della popolazione \" + \\\n",
        "    \"dello stato. A Doha vi è la sede del governo del Qatar, il cui capo è l'emiro Tamim bin \" + \\\n",
        "    \"Hamad al-Thani. Nei pressi della città sorge Education City, una zona in cui si sono \" + \\\n",
        "    \"insediati diversi campus universitari e istituti dedicati alla ricerca e all'innovazione. \" + \\\n",
        "    \"La città presenta un carattere cosmopolita. A Doha è stanziato il principale quartier \" + \\\n",
        "    \"generale del Comando centrale militare USA, il più grande dell'intero Medio Oriente. \"\n",
        "\n",
        "nlp = Italian()\n",
        "nlp.add_pipe(\"sentencizer\")\n",
        "doc = nlp(text)\n",
        "for sent in doc.sents:\n",
        "    print(sent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hjjubsZXlOZe"
      },
      "outputs": [],
      "source": [
        "# We need a list of documents as it's iterable\n",
        "training_corpus = []\n",
        "for i, text in enumerate(doc.sents):\n",
        "    tagged_doc = TaggedDocument(simple_preprocess(text.text), [i])\n",
        "    training_corpus.append(tagged_doc)\n",
        "print(training_corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GkyM6AMGlOZe"
      },
      "outputs": [],
      "source": [
        "# Instantiating and training the object, all at once\n",
        "model = Doc2Vec(training_corpus, vector_size=100, window=2, min_count=1, workers=num_cores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olXJGPLklOZf"
      },
      "source": [
        "## Inferring a  vector for a new document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z9sPuKNglOZg"
      },
      "outputs": [],
      "source": [
        "# your homework also belongs here (and it should be, again, one line)\n",
        "model.infer_vector(simple_preprocess('Doha è la più grande città del Qatar'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nPuXe6rplOZg"
      },
      "outputs": [],
      "source": [
        "# Legacy version (for an older version of gensim)\n",
        "# It's going to trigger an error!\n",
        "# To avoid the error, drop iter and steps\n",
        "\n",
        "# corpus = [\"The faster Harry got to the store, the faster and faster Harry would get home.\"]\n",
        "# corpus.append(\"Harry is hairy and faster than Jill.\")\n",
        "# corpus.append(\"Jill is not as hairy as Harry.\")\n",
        "\n",
        "# training_corpus = []\n",
        "# for i, text in enumerate(corpus):\n",
        "#     tagged_doc = TaggedDocument(simple_preprocess(text), [i])\n",
        "#     training_corpus.append(tagged_doc)\n",
        "# print(training_corpus)\n",
        "\n",
        "# # Instantiating the object\n",
        "# model = Doc2Vec(vector_size=100,   # dimensions of the vectors\n",
        "#                 min_count=2, # min frequency for the tokens\n",
        "#                 workers=num_cores,\n",
        "#                 iter=10)   # number of iterations\n",
        "# # Compiling the vocabulary\n",
        "# model.build_vocab(training_corpus)\n",
        "\n",
        "# model.infer_vector(simple_preprocess('Indeed Jill is the fastest'), steps=10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3d-eVK6nlOZh"
      },
      "source": [
        "# Homework\n",
        "\n",
        "1. Plug the proper tokenisation for Italian from spacy (instead of gensim's crude)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**End of the notebook**"
      ],
      "metadata": {
        "id": "0zuspHxCmkbR"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}