---
title: Overview of the CLEF-2021 CheckThat! Lab on Detecting Check-Worthy Claims,
  Previously Fact-Checked Claims, and Fake News
authors:
- Preslav Nakov
- Giovanni Da San Martino
- Tamer Elsayed
- Alberto Barrón-Cedeño
- Ruben Miguez
- Shaden Shaar
- Firoj Alam
- Fatima Haouari
- Maram Hasanain
- Watheq Mansour
- Bayan Hamdan
- Zien Sheikh Ali
- Nikolay Babulkov
- Alex Nikolov
- Gautam Kishore Shahi
- Julia Maria Struss
- Thomas Mandl
- Mucahid Kutlu
- Yavuz Selim Kartal
date: '2021-01-01'
publishDate: '2025-03-26T11:17:11.817558Z'
publication_types:
- paper-conference
publication: '*EXPERIMENTAL IR MEETS MULTILINGUALITY, MULTIMODALITY, AND  INTERACTION,
  CLEF 2021*'
doi: 10.1007/978-3-030-85251-1_19
abstract: 'We describe the fourth edition of the CheckThat! Lab, part of the  2021
  Conference and Labs of the Evaluation Forum (CLEF). The lab evaluates technology
  supporting tasks related to factuality, and covers Arabic,   Bulgarian, English,
  Spanish, and Turkish. Task 1 asks to predict which posts in a Twitter stream are
  worth fact-checking, focusing on COVID-19 and politics (in all five languages).
  Task 2 asks to determine whether a claim in a tweet can be verified using a set
  of previously fact-checked claims (in Arabic and English). Task 3 asks to predict
  the veracity of a news article and its topical domain (in English). The evaluation
  is based on  mean average precision or precision at rank k for the ranking tasks,
  and macro-F1 for the classification tasks. This was the most popular CLEF-2021 lab
  in terms of team registrations: 132 teams. Nearly one-third of them participated:
  15, 5, and 25 teams submitted official runs for tasks 1, 2, and 3, respectively.'
---
