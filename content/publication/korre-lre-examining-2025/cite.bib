@article{Korre_LRE_examining:2025,
 abstract = {This study examines whether the psycholinguistic and demographic 
characteristics of authors of online texts are correlated with the way 
harmful language, such as toxicity and hate speech, is judged. We apply 
artificial intelligence models to two harmful language datasets, Jigsaw’s 
Special Rater Pool dataset and the Measuring Hate Speech dataset, to generate 
probabilities for different text aspects, namely inferring demographic 
information of the author behind the suspicious text in terms of age and 
gender, as well as the expressed emotions, emotionality, sentiment and 
communication style. We then perform a statistical regression analysis to 
examine how these text aspects correlate with the perception of hate speech 
and toxicity during the annotation process. The study shows that while the 
frequency of the psycholinguistic text aspects that can be derived from the 
author’s personality does not differ significantly between harmful and 
non-harmful classes, the inferred text aspects are statistically associated 
with the annotators’ perception of harmful language and could potentially 
influence the way annotators label the texts.},
 author = {Korre, Katerina and
Basile, Angelo and
Yenikent, Seren and
Spallaccia, Beatrice and 
Franco-Salvador, Marc and 
Barrón-Cedeño, Alberto},
 doi = {10.1007/s10579-025-09822-7},
 issn = {1574-0218},
 journal = {Language Resources and Evaluation},
 keywords = {},
 pages = {},
 title = {Examining inferred author and textual correlates of harmful language 
annotation},
 url = {https://doi.org/10.1007/s10579-025-09822-7},
 volume = {},
 year = {2025}
}
