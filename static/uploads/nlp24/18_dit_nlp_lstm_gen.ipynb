{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3D8-ctSLCHsX"
      },
      "source": [
        "# DIT NLP lesson 2024\n",
        "\n",
        "## Generating text with LSTMs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZdPP-P-OCHsb"
      },
      "outputs": [],
      "source": [
        "# Run only the first time\n",
        "import nltk\n",
        "nltk.download('gutenberg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BC3nGzodCHsd"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import sys\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.layers import LSTM\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# In previous versions of Keras, the import was...\n",
        "# from keras.optimizers import RMSprop"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import gutenberg\n",
        "gutenberg.fileids()"
      ],
      "metadata": {
        "id": "MKHuSqY4CYGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuXYZ_sWCHsd"
      },
      "source": [
        "Go to [Project Gutenberg](https://www.gutenberg.org) if you want more"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "vOiau9KHCHse"
      },
      "outputs": [],
      "source": [
        "text = ''\n",
        "for txt in gutenberg.fileids():\n",
        "    if 'shakespeare' in txt:\n",
        "        text += gutenberg.raw(txt).lower()\n",
        "chars = sorted(list(set(text)))\n",
        "\n",
        "# dictionary from character to index\n",
        "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "\n",
        "# distionary from index to character\n",
        "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
        "\n",
        "print('corpus length: {} total chars: {}'.format(len(text), len(chars)))\n",
        "\n",
        "print(text[:500])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fwes4IDICHse"
      },
      "source": [
        "**Objective.** Predicting the character after having seen 40 characters\n",
        "\n",
        "**Trick.** Adding redundancy to the training collection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LYv1--O7CHse"
      },
      "outputs": [],
      "source": [
        "maxlen = 40\n",
        "step = 3\n",
        "sentences = []\n",
        "next_chars = []\n",
        "# Notice: no tokenisation; no sentence splitting; no linebreak elimination\n",
        "for i in range(0, len(text) - maxlen, step):\n",
        "    sentences.append(text[i: i + maxlen])\n",
        "    next_chars.append(text[i + maxlen])\n",
        "print('Total number of sequences:', len(sentences))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uUlxlDflCHse"
      },
      "outputs": [],
      "source": [
        "# How does an instance look like?\n",
        "\n",
        "idx = [0, 5, 2555, 10000, 12365]\n",
        "\n",
        "for i in idx:\n",
        "    print(i)\n",
        "    print(sentences[i], \" --> \", next_chars[i])\n",
        "    print(\"=\"*50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tITiujcaCHsf"
      },
      "outputs": [],
      "source": [
        "# Producing the one-hot encoding\n",
        "X = np.zeros((len(sentences), maxlen, len(chars)), dtype=bool)\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=bool)\n",
        "\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence):\n",
        "        X[i, t, char_indices[char]] = 1\n",
        "    y[i, char_indices[next_chars[i]]] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qTAIfFxSCHsg"
      },
      "outputs": [],
      "source": [
        "# Building the model\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(128,\n",
        "    input_shape=(maxlen, len(chars))))\n",
        "\n",
        "model.add(Dense(len(chars)))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "# https://keras.io/api/optimizers/rmsprop/; learning rate default: 0.001\n",
        "# learning_rate used to be lr in previous versions\n",
        "optimizer = RMSprop(learning_rate=0.01)\n",
        "\n",
        "# no more binary cross entropy; no dropout (we \"kind of\" want to overfit here)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rB8tDAdsCHsg"
      },
      "outputs": [],
      "source": [
        "# Training\n",
        "epochs = 6\n",
        "batch_size = 128\n",
        "model_structure = model.to_json()\n",
        "\n",
        "with open(\"shakes_lstm_model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_structure)\n",
        "\n",
        "for i in range(5):\n",
        "    model.fit(X, y,\n",
        "        batch_size=batch_size,\n",
        "        epochs=epochs\n",
        "    )\n",
        "    model.save_weights(\"shakes_lstm_{}.weights.h5\".format(i+1))\n",
        "\n",
        "# It should take about 25 epochs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjqffePACHsg"
      },
      "source": [
        "**Temperature**\n",
        "\n",
        "temperature > 1 : more diverse outcome\n",
        "\n",
        "temperature < 1 : more strict (try to \"copy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4w6jHFcKCHsh"
      },
      "outputs": [],
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    \"\"\"Sampler to generate character sequences\"\"\"\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "\n",
        "    # produces a number of random outcomes,\n",
        "    # given a probability distribution\n",
        "    # n=1    number of experiments\n",
        "    # preds  sequence of probabilities\n",
        "    # size=1\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DlPON3vOCHsh"
      },
      "outputs": [],
      "source": [
        "start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
        "    print()\n",
        "    print('----- diversity:', diversity)\n",
        "    # Getting a random starting text\n",
        "    sentence = text[start_index: start_index + maxlen]\n",
        "    generated = ''\n",
        "    generated += sentence\n",
        "\n",
        "    print('----- Generating with seed: \"' + sentence + '\"')\n",
        "    sys.stdout.write(generated)\n",
        "    for i in range(400):\n",
        "        # one-hot representation\n",
        "        x = np.zeros((1, maxlen, len(chars)))\n",
        "        for t, char in enumerate(sentence):\n",
        "            x[0, t, char_indices[char]] = 1.\n",
        "\n",
        "        # Producing the prediction\n",
        "        preds = model.predict(x, verbose=0)[0]\n",
        "        next_index = sample(preds, diversity)\n",
        "\n",
        "        # looking up the next character and adding it\n",
        "        next_char = indices_char[next_index]\n",
        "        generated += next_char\n",
        "\n",
        "        #updating the seed\n",
        "        sentence = sentence[1:] + next_char\n",
        "\n",
        "        sys.stdout.write(next_char)\n",
        "        sys.stdout.flush()  # to display it right away\n",
        "    print()\n",
        "\n",
        "# lower values should look \"more Shakesperean\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWi-OiwBCHsi"
      },
      "source": [
        "That's **70,200** parameters in the LSTM (against **17,550** for the RNN)\n",
        "\n",
        "Back to the slides"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RP97yLmhCHsi"
      },
      "source": [
        "## Homework\n",
        "\n",
        "1. Try with shorter/longer contextual sequences\n",
        "2. Build a model that try to mimic Dante"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2DiRLyqCHsi"
      },
      "source": [
        "**End of the notebook**"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}