{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# DIT NLP lesson 2024"
      ],
      "metadata": {
        "id": "GlqdI6W5vjRT"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QnmNnOA9vaVo"
      },
      "source": [
        "# A gentle introduction to neural networks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NLAZhePSvaVt"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "from random import random\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JvgRtYdQvaVw"
      },
      "outputs": [],
      "source": [
        "# Input\n",
        "example_input   = [1, .2, .1, .05, .2]\n",
        "input_vector = np.array(example_input)\n",
        "\n",
        "# Input weights\n",
        "example_weights = [.2, .12, .4, .6, .90]\n",
        "weights = np.array(example_weights)\n",
        "\n",
        "# Bias weights\n",
        "bias_weight = .25\n",
        "\n",
        "# Just a dot product (+ the bias)\n",
        "activation_level = np.dot(input_vector, weights) + (bias_weight * 1)\n",
        "activation_level"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hiW-_GE1vaVx"
      },
      "outputs": [],
      "source": [
        "# Activation function\n",
        "threshold = 0.5\n",
        "if activation_level >= threshold:\n",
        "    perceptron_output = 1\n",
        "else:\n",
        "    perceptron_output = 0\n",
        "# There is an error in this line of the book!\n",
        "perceptron_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocwasubavaVz"
      },
      "source": [
        "**Back to the slides**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1TUsYtAvaVz"
      },
      "source": [
        "## The kind of functions that $y=w^T x$ can learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-xEq7_EevaV0"
      },
      "outputs": [],
      "source": [
        "for i in range(-4, 5, 2):\n",
        "    fig, ax = plt.subplots(figsize=(5,5))\n",
        "    ax.spines['left'].set_position('center')\n",
        "    ax.spines['bottom'].set_position('center')\n",
        "    # Eliminate upper and right axes\n",
        "    ax.spines['right'].set_color('none')\n",
        "    ax.spines['top'].set_color('none')\n",
        "\n",
        "    ax.set(title='$y=w^Tx$')\n",
        "    x = np.arange(-10.0, 10.0, 0.01)\n",
        "\n",
        "    plt.xlim((-11,+11))\n",
        "    plt.ylim((-11,+11))\n",
        "    ax.set(title='$y={}x$'.format(i))\n",
        "    y = i*x\n",
        "    ax.plot(x, y)\n",
        "\n",
        "    fig.savefig(\"linear_w{}.png\".format(i))\n",
        "    plt.show()\n",
        "    # plt.clf()\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yW2FD57dvaV1"
      },
      "source": [
        "## The kind of functions that $y=w^T x +b$ can learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lGxROhyFvaV2"
      },
      "outputs": [],
      "source": [
        "for i in range(-4, 5, 2):\n",
        "    fig, ax = plt.subplots(figsize=(5,5))\n",
        "    ax.spines['left'].set_position('center')\n",
        "    ax.spines['bottom'].set_position('center')\n",
        "    # Eliminate upper and right axes\n",
        "    ax.spines['right'].set_color('none')\n",
        "    ax.spines['top'].set_color('none')\n",
        "\n",
        "    ax.set(title='$y=w^Tx$')\n",
        "    x = np.arange(-10.0, 10.0, 0.01)\n",
        "\n",
        "    plt.xlim((-11,+11))\n",
        "    plt.ylim((-11,+11))\n",
        "    ax.set(title='$y=x + {}$'.format(i))\n",
        "    y = x + i\n",
        "    ax.plot(x, y)\n",
        "\n",
        "    fig.savefig(\"linear_b{}.png\".format(i))\n",
        "    plt.show()\n",
        "    # plt.clf()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kt2SXeMlvaV4"
      },
      "source": [
        "## Learning an OR function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h44LXEs6vaV4"
      },
      "outputs": [],
      "source": [
        "# Data: input and expected output\n",
        "sample_data = [\n",
        "        [0, 0], # False, False\n",
        "        [0, 1], # False, True\n",
        "        [1, 0], # True, False\n",
        "        [1, 1]  # True, True\n",
        "        ]\n",
        "expected_results = [0, # (False OR False) --> False\n",
        "                    1, # (False OR True)  --> True\n",
        "                    1, # (True OR False)  --> True\n",
        "                    1] # (True OR True )  --> True\n",
        "activation_threshold = 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HpY4Slr2vaV5"
      },
      "outputs": [],
      "source": [
        "# Initialising the weights with a small random float 0 < w < .001\n",
        "weights = np.random.random(2)/1000\n",
        "bias_weight = np.random.random() / 1000\n",
        "\n",
        "print(\"weights:\\t\", weights)\n",
        "print(\"bias weight:\\t\", bias_weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "USNvHTShvaV6"
      },
      "outputs": [],
      "source": [
        "# Random guessing (~zero-shot)\n",
        "for idx, sample in enumerate(sample_data):\n",
        "    input_vector = np.array(sample)\n",
        "    activation_level = np.dot(input_vector, weights) + (bias_weight * 1)\n",
        "    if activation_level > activation_threshold:\n",
        "        perceptron_output = 1\n",
        "    else:\n",
        "        perceptron_output = 0\n",
        "    print('Input: [{},{}]'.format(sample[0], sample[1]))\n",
        "    print('Expected: {}'.format(expected_results[idx]))\n",
        "    print('Predicted {}\\n'.format(perceptron_output))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-K7-f9-ZvaV7"
      },
      "source": [
        "### Adjusting the weights\n",
        "\n",
        "We are doing this with a for loop, which is not efficient at all!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nWa-E1xkvaV7"
      },
      "outputs": [],
      "source": [
        "# Training for 50 epochs\n",
        "epochs = 50\n",
        "for iteration_num in range(epochs):\n",
        "    correct_answers = 0\n",
        "    for idx, sample in enumerate(sample_data):\n",
        "        # Dot product plus bias\n",
        "        input_vector = np.array(sample)\n",
        "        weights = np.array(weights)\n",
        "        activation_level = np.dot(input_vector, weights) + (bias_weight * 1)\n",
        "\n",
        "        # Fires or not?\n",
        "        if activation_level > activation_threshold:\n",
        "            perceptron_output = 1\n",
        "        else:\n",
        "            perceptron_output = 0\n",
        "\n",
        "        # The prediction is correct?\n",
        "        if perceptron_output == expected_results[idx]:\n",
        "            correct_answers += 1\n",
        "\n",
        "        # Updating the weights (if necessary!)\n",
        "        new_weights = []\n",
        "        for i, x in enumerate(sample):\n",
        "            new_weights.append(weights[i] + (expected_results[idx] - perceptron_output) * x)\n",
        "\n",
        "        bias_weight = bias_weight + ((expected_results[idx] - perceptron_output) * 1)\n",
        "        weights = np.array(new_weights)\n",
        "\n",
        "    print('epoch {}: {} correct answers out of 4'.format(iteration_num, correct_answers))\n",
        "print(\"\\nEnd of the learning process\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiN-G2kivaV8"
      },
      "source": [
        "**Back to the slides**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDyAJwQDvaV8"
      },
      "source": [
        "## _Learning_ an XOR function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RUV1relSvaV8"
      },
      "outputs": [],
      "source": [
        "# Data: input and expected output\n",
        "sample_data = [\n",
        "    [0, 0],\n",
        "    [0, 1],\n",
        "    [1, 0],\n",
        "    [1, 1]\n",
        "  ]\n",
        "expected_results = [0,\n",
        "                    1,\n",
        "                    1,\n",
        "                    0] # The one and only change!\n",
        "activation_threshold = 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PTYCfTDOvaV9"
      },
      "outputs": [],
      "source": [
        "# Initialising the weights with a small random float 0 < w < .001\n",
        "weights = np.random.random(2)/1000\n",
        "bias_weight = np.random.random() / 1000\n",
        "\n",
        "print(\"weights:\\t\", weights)\n",
        "print(\"bias weight:\\t\", bias_weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q7LhyhCCvaV9"
      },
      "outputs": [],
      "source": [
        "epochs = 100\n",
        "for iteration_num in range(epochs):\n",
        "    correct_answers = 0\n",
        "    for idx, sample in enumerate(sample_data):\n",
        "        input_vector = np.array(sample)\n",
        "        weights = np.array(weights)\n",
        "        activation_level = np.dot(input_vector, weights) + (bias_weight * 1)\n",
        "\n",
        "        if activation_level > activation_threshold:\n",
        "            perceptron_output = 1\n",
        "        else:\n",
        "            perceptron_output = 0\n",
        "\n",
        "        if perceptron_output == expected_results[idx]:\n",
        "            correct_answers += 1\n",
        "\n",
        "        # updating all weights\n",
        "        new_weights = []\n",
        "        for i, x in enumerate(sample):\n",
        "            new_weights.append(weights[i] + (expected_results[idx] - perceptron_output) * x)\n",
        "\n",
        "        bias_weight = bias_weight + ((expected_results[idx] - perceptron_output) * 1)\n",
        "        weights = np.array(new_weights)\n",
        "\n",
        "    print('epoch {}: {} correct answers out of 4'.format(iteration_num, correct_answers))\n",
        "\n",
        "print(\"\\nEnd of the (lack of) learning process\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lei81yHRvaV-"
      },
      "source": [
        "**End of the notebook**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OaWq0xkBvaV-"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}